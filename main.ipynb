{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db65f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70eeb6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'People': 0, 'Motorbike': 1, 'Cup': 2, 'Bicycle': 3, 'Chair': 4, 'Boat': 5, 'Table': 6, 'Car': 7, 'Bottle': 8, 'Bus': 9, 'Cat': 10, 'Dog': 11}\n"
     ]
    }
   ],
   "source": [
    "IMG_PATH = Path(r'./data/img_dataset')\n",
    "train_val_test = (0.8,0.1,0.1)\n",
    "ANNOTATION_PATH = Path(r'./data/annotation')\n",
    "YOLO_ANNOTATION = Path(r'./data/yolo_annotation')\n",
    "\n",
    "class_dict = {category_name: idx for idx, category_name in enumerate(os.listdir(IMG_PATH))}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "297a529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_yaml(path='./'):\n",
    "    data = {\n",
    "        'path': path,\n",
    "        'train': './data/train_data',\n",
    "        'val': './data/val_data',\n",
    "        'nc': len(class_dict),\n",
    "        'names': list(class_dict.keys()),\n",
    "    }\n",
    "\n",
    "    with open('data.yaml', 'w') as f:\n",
    "        yaml.dump(data, f, default_flow_style=False)\n",
    "\n",
    "# Example usage\n",
    "create_data_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc2af254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/annotation/Bicycle/2015_00391.jpg.txt cannot be read.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3029.729] global loadsave.cpp:268 findDecoder imread_('data/img_dataset/Bicycle/2015_00391.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "def corresponding_image_path(folder_path, annotaion_path):\n",
    "    file_title, _ = os.path.splitext(annotaion_path)\n",
    "    return IMG_PATH / folder_path / file_title\n",
    "\n",
    "def pascal_to_yolo():\n",
    "    for sub_category in os.listdir(ANNOTATION_PATH):\n",
    "        folder_path = ANNOTATION_PATH / sub_category\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = folder_path / file_name\n",
    "            \n",
    "            yolo_annotation_path = YOLO_ANNOTATION/sub_category/file_name\n",
    "            if os.path.isfile(yolo_annotation_path):\n",
    "                continue\n",
    "\n",
    "            os.makedirs(YOLO_ANNOTATION/sub_category, exist_ok=True)\n",
    "\n",
    "            image_path = corresponding_image_path(sub_category, file_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                print(f\"{file_path} cannot be read.\")\n",
    "                continue\n",
    "\n",
    "            img_width, img_height = img.shape[:2]\n",
    "\n",
    "            with open(file_path, 'r') as anno_file:\n",
    "                pascal_data = anno_file.readlines()[1:]\n",
    "\n",
    "            pascal_num = list(map(lambda s: s.strip().split(\" \")[:5], pascal_data))\n",
    "            \n",
    "            yolo_format = []\n",
    "            for indv_bounding_coordinates in pascal_num:\n",
    "                indv_bounding_coordinates[0] = class_dict[indv_bounding_coordinates[0]]\n",
    "                indv_bounding_coordinates[1:] = list(map(int, indv_bounding_coordinates[1:]))\n",
    "\n",
    "                cv2.rectangle(img, \n",
    "                              (indv_bounding_coordinates[1], indv_bounding_coordinates[2]), \n",
    "                              (indv_bounding_coordinates[1]+indv_bounding_coordinates[3],indv_bounding_coordinates[2]+indv_bounding_coordinates[4]),\n",
    "                              color=(0,200,0),\n",
    "                              thickness=2\n",
    "                              )\n",
    "                \n",
    "\n",
    "                class_category = indv_bounding_coordinates[0]\n",
    "                x_ctr = (indv_bounding_coordinates[1] + indv_bounding_coordinates[3]/2) / img_width\n",
    "                y_ctr = (indv_bounding_coordinates[2] + indv_bounding_coordinates[4]/2) / img_height\n",
    "                width = (indv_bounding_coordinates[3]) / img_width\n",
    "                height = (indv_bounding_coordinates[4]) / img_height\n",
    "\n",
    "                yolo_format.append([class_category, x_ctr, y_ctr, width, height])\n",
    "            \n",
    "            # cv2.imshow(str(file_path), img)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            with open(yolo_annotation_path, 'w') as yolo_writer:\n",
    "                for data in yolo_format:\n",
    "                    yolo_writer.write(f\"{' '.join(list(map(str, data)))}\\n\")\n",
    "                \n",
    "            \n",
    "\n",
    "pascal_to_yolo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a90b00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names': ['People', 'Motorbike', 'Cup', 'Bicycle', 'Chair', 'Boat', 'Table', 'Car', 'Bottle', 'Bus', 'Cat', 'Dog'], 'nc': 12, 'path': './', 'train': './data/train_data', 'val': './data/val_data'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33fdcd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 129 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n",
      "(129, 3157200, 0, 8.8575488)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('./snapshots/yolov8n.pt')\n",
    "\n",
    "print(model.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2830698",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_settings = {\n",
    "    # Output Config\n",
    "    \"project\": \"./YOLOv8_outputs/runs/train\",\n",
    "    \"name\": \"yolov8_exp\",\n",
    "\n",
    "    # Train Config\n",
    "    \"epochs\": 1000,\n",
    "    \"patience\": 10,\n",
    "    \"batch\": -1,\n",
    "    \"imgsz\": 640,\n",
    "    \"save\": True,\n",
    "    \"save_period\": 1,\n",
    "    \"cache\": False,\n",
    "    \"device\": 0,\n",
    "    \"workers\": 8,\n",
    "    \"project\": \"runs/train\",\n",
    "    \"name\": \"yolov8_exp\",\n",
    "    \"exist_ok\": True,\n",
    "    \"pretrained\": True,\n",
    "    \"optimizer\": \"auto\",\n",
    "    \"deterministic\": False,\n",
    "    \"classes\":list(class_dict.keys()),\n",
    "    \"rect\": False,\n",
    "    \"resume\": True,\n",
    "    \"visualize\": True,\n",
    "\n",
    "    # \"lr0\": 0.001,\n",
    "    # \"lrf\": 0.01,\n",
    "    # \"momentum\": 0.937,\n",
    "    # \"weight_decay\": 0.0005,\n",
    "    # \"warmup_epochs\": 3.0,\n",
    "    # \"warmup_momentum\": 0.8,\n",
    "    # \"warmup_bias_lr\": 0.1,\n",
    "    # \"box\": 7.5,\n",
    "    # \"cls\": 0.5,\n",
    "    # \"dfl\": 1.5,\n",
    "\n",
    "    # Augmentation Config\n",
    "    \"hsv_h\": 0.015,\n",
    "    \"hsv_s\": 0.7,\n",
    "    \"hsv_v\": 0.4,\n",
    "    \"degrees\": 0.0,\n",
    "    \"translate\": 0.1,\n",
    "    \"scale\": 0.5,\n",
    "    \"shear\": 0.0,\n",
    "    \"perspective\": 0.0,\n",
    "    \"flipud\": 0.0,\n",
    "    \"fliplr\": 0.5,\n",
    "    \"mosaic\": 1.0,\n",
    "    \"mixup\": 0.0,\n",
    "    \"copy_paste\": 0.0,\n",
    "    \"dropout\": 0.0,\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "124f338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.107 🚀 Python-3.10.17 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce GTX 1080, 8106MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=snapshots/yolov8n.pt, data=data.yaml, epochs=500, time=None, patience=50, batch=-1, imgsz=640, save=True, save_period=-1, cache=disk, device=0, workers=8, project=YOLOv8, name=yolov8n, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=snapshots/yolov8n.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, conf=0.001, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=ultralytics/assets/, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, image_weights=False, save_hybrid=False, hide_labels=False, hide_conf=False, line_thickness=3, fl_gamma=0.0, label_smoothing=0.0, v5loader=True, save_dir=YOLOv8/yolov8n\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'data.yaml' error ❌ \nDataset 'data.yaml' images not found ⚠️, missing path '/home/yc-family/Documents/code/mlgp_new/datasets/data/val_data'\nNote dataset download directory is '/home/yc-family/Documents/code/mlgp_new/datasets'. You can update this in '/home/yc-family/.config/Ultralytics/settings.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/code/mlgp/.venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:582\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    581\u001b[0m }:\n\u001b[0;32m--> 582\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m~/Documents/code/mlgp/.venv/lib/python3.10/site-packages/ultralytics/data/utils.py:372\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    371\u001b[0m     m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote dataset download directory is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can update this in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSETTINGS_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(m)\n\u001b[1;32m    373\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset 'data.yaml' images not found ⚠️, missing path '/home/yc-family/Documents/code/mlgp_new/datasets/data/val_data'\nNote dataset download directory is '/home/yc-family/Documents/code/mlgp_new/datasets'. You can update this in '/home/yc-family/.config/Ultralytics/settings.json'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_settings\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/mlgp/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:785\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    783\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[0;32m~/Documents/code/mlgp/.venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:137\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/mlgp/.venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:586\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msingle_cls:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset 'data.yaml' error ❌ \nDataset 'data.yaml' images not found ⚠️, missing path '/home/yc-family/Documents/code/mlgp_new/datasets/data/val_data'\nNote dataset download directory is '/home/yc-family/Documents/code/mlgp_new/datasets'. You can update this in '/home/yc-family/.config/Ultralytics/settings.json'"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data=\"data.yaml\",\n",
    "    **config_settings\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
