{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db65f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import yaml\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70eeb6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bicycle': 0, 'Boat': 1, 'Bottle': 2, 'Bus': 3, 'Car': 4, 'Cat': 5, 'Chair': 6, 'Cup': 7, 'Dog': 8, 'Motorbike': 9, 'People': 10, 'Table': 11}\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0) # Set to your desired GPU number\n",
    "IMG_PATH = Path(r'./data/img_dataset')\n",
    "ANNOTATION_PATH = Path(r'./data/annotation')\n",
    "train_val_test = (0.8,0.1,0.1)\n",
    "\n",
    "class_dict = {category_name: idx for idx, category_name in enumerate(os.listdir(IMG_PATH))}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1897d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dataset(target_dataset):\n",
    "    base_dataset = r'./data/img_dataset'\n",
    "    os.makedirs(target_dataset, exist_ok=True)\n",
    "    for category_name in os.listdir(base_dataset):\n",
    "        os.makedirs(os.path.join(target_dataset, category_name), exist_ok=True)\n",
    "        for img_name in os.listdir(os.path.join(base_dataset, category_name)):\n",
    "            shutil.copy(os.path.join(base_dataset, category_name, img_name), os.path.join(target_dataset, category_name, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "793b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pascal_to_yolo(image_path):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    image_dir = os.path.dirname(image_path).replace(\"\\\\\", \"/\")\n",
    "    file_title, _ = os.path.splitext(image_name)\n",
    "    yolo_anno_path = image_dir.replace(\"images\", \"labels\") + f\"/{file_title}.txt\"\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img_height, img_width = img.shape[:2]\n",
    "\n",
    "    sub_category = image_dir.split(\"/\")[-1]\n",
    "    path_from_base = os.path.join(sub_category, image_name)\n",
    "    \n",
    "    original_annotation_path = os.path.join(ANNOTATION_PATH, path_from_base + \".txt\")\n",
    "    with open(original_annotation_path, 'r') as anno_file:\n",
    "        pascal_data = anno_file.readlines()[1:]\n",
    "\n",
    "    pascal_num = list(map(lambda s: s.strip().split(\" \")[:5], pascal_data))\n",
    "    \n",
    "    yolo_format = []\n",
    "    for indv_bounding_coordinates in pascal_num:\n",
    "        indv_bounding_coordinates[0] = class_dict[indv_bounding_coordinates[0]]\n",
    "        indv_bounding_coordinates[1:] = list(map(int, indv_bounding_coordinates[1:]))\n",
    "        # print(indv_bounding_coordinates)\n",
    "\n",
    "        class_category = indv_bounding_coordinates[0]\n",
    "        x_ctr = min((indv_bounding_coordinates[1] + indv_bounding_coordinates[3]/2) / img_width, 1.0)\n",
    "        y_ctr = min((indv_bounding_coordinates[2] + indv_bounding_coordinates[4]/2) / img_height, 1.0)\n",
    "        width = min((indv_bounding_coordinates[3]) / img_width, 1.0)\n",
    "        height = min((indv_bounding_coordinates[4]) / img_height, 1.0)\n",
    "        yolo_format.append([class_category, x_ctr, y_ctr, width, height])\n",
    "    \n",
    "    os.makedirs(os.path.dirname(yolo_anno_path), exist_ok=True)\n",
    "    with open(yolo_anno_path, 'w') as yolo_writer:\n",
    "        for data in yolo_format:\n",
    "            yolo_writer.write(f\"{' '.join(list(map(str, data)))}\\n\")\n",
    "    \n",
    "    print(f\"Converted to {image_path} and label {yolo_anno_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a358365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test(src_path, train_path, val_path, test_path, split_ratio, function=None, seed=None):\n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "    if not os.path.exists(val_path):\n",
    "        os.makedirs(val_path, exist_ok=True)\n",
    "    if not os.path.exists(test_path):\n",
    "        os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "    if os.listdir(train_path) != []:\n",
    "        shutil.rmtree(train_path)\n",
    "        print(f\"Removed existing train path: {train_path}\")\n",
    "    if os.listdir(val_path) != []:\n",
    "        shutil.rmtree(val_path)\n",
    "        print(f\"Removed existing val path: {val_path}\")\n",
    "    if os.listdir(test_path) != []:\n",
    "        shutil.rmtree(test_path)\n",
    "        print(f\"Removed existing test path: {test_path}\")\n",
    "    \n",
    "    if seed != None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    file_lists = []\n",
    "    for (root, _, file_names) in os.walk(src_path):\n",
    "        if file_names == []:\n",
    "            continue\n",
    "\n",
    "        sub_folder_name = os.path.basename(root)\n",
    "\n",
    "        file_path_list = list(map(lambda path: os.path.join(sub_folder_name, path), file_names))\n",
    "\n",
    "        random.shuffle(file_path_list)\n",
    "        file_lists.append(file_path_list)\n",
    "\n",
    "    for category_specific_list in file_lists:\n",
    "        for file_name in category_specific_list:\n",
    "            random_num = random.random()\n",
    "\n",
    "            if random_num < split_ratio[0]:\n",
    "                move_path = os.path.join(train_path, os.path.dirname(file_name))\n",
    "            elif random_num < sum(split_ratio[:2]):\n",
    "                move_path = os.path.join(val_path, os.path.dirname(file_name)) \n",
    "            else:\n",
    "                move_path = os.path.join(test_path, os.path.dirname(file_name))\n",
    "\n",
    "            os.makedirs(move_path, exist_ok=True)            \n",
    "            original_path = os.path.join(src_path, file_name)\n",
    "            new_name = os.path.join(move_path, os.path.basename(file_name))\n",
    "            shutil.copy(original_path, move_path)\n",
    "            if function != None:\n",
    "                function(move_path)\n",
    "                \n",
    "\n",
    "            pascal_to_yolo(new_name)\n",
    "            \n",
    "            print(f\"{original_path} --> {new_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6f65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for different file names for images and labels\n",
    "\n",
    "def check_file_names(folder): # test_data or train_val\n",
    "    img_folder = os.path.join(folder, \"images\")\n",
    "    label_folder = os.path.join(folder, \"labels\")\n",
    "    train_img = os.path.join(img_folder, \"train\")\n",
    "    val_img = os.path.join(img_folder, \"val\")\n",
    "    train_label = os.path.join(label_folder, \"train\")\n",
    "    val_label = os.path.join(label_folder, \"val\")\n",
    "\n",
    "    for (root, dirname, filename) in os.walk(train_img):\n",
    "        for objtype in dirname:\n",
    "            obj_path = os.path.join(root, objtype)\n",
    "            for (root, dirname, file_names) in os.walk(obj_path):\n",
    "                for file_name in file_names:\n",
    "                    file_name = os.path.splitext(file_name)[0]\n",
    "                    label_name = os.path.join(train_label, objtype, file_name + \".txt\")\n",
    "                    if not os.path.exists(label_name):\n",
    "                        print(f\"Missing label file for {file_name} in {label_name}\")\n",
    "    \n",
    "    for (root, dirname, filename) in os.walk(val_img):\n",
    "        for objtype in dirname:\n",
    "            obj_path = os.path.join(root, objtype)\n",
    "            for (root, dirname, file_names) in os.walk(obj_path):\n",
    "                for file_name in file_names:\n",
    "                    file_name = os.path.splitext(file_name)[0]\n",
    "                    label_name = os.path.join(val_label, objtype, file_name + \".txt\")\n",
    "                    if not os.path.exists(label_name):\n",
    "                        print(f\"Missing label file for {file_name} in {label_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63445c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check label files if width and height >1\n",
    "def check_label_files(folder):\n",
    "\n",
    "    label_folder = os.path.join(folder, \"labels\")\n",
    "    print(label_folder)\n",
    "    for root, dirname, files in os.walk(label_folder):\n",
    "        if files == []:\n",
    "            continue\n",
    "        for file in files:\n",
    "            if \"cache\" in file:\n",
    "                continue\n",
    "            \n",
    "            label_path = os.path.join(root, file)\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                new_lines = []\n",
    "                for line in lines:\n",
    "                    values = list(map(float, line.strip().split()))\n",
    "                    if values[1] > 1 or values[2] > 1 or values[3] > 1 or values[4] > 1:\n",
    "                        values[1] = 1.0 if values[1] > 1 else values[1]\n",
    "                        values[2] = 1.0 if values[2] > 1 else values[2]\n",
    "                        values[3] = 1.0 if values[3] > 1 else values[3]\n",
    "                        values[4] = 1.0 if values[4] > 1 else values[4]\n",
    "                        print(f\"Invalid bounding box in {label_path}: {line.strip()}\")\n",
    "                    if values[1] < 0 or values[2] < 0 or values[3] < 0 or values[4] < 0:\n",
    "                        values[1] = 0.0 if values[1] < 0 else values[1]\n",
    "                        values[2] = 0.0 if values[2] < 0 else values[2]\n",
    "                        values[3] = 0.0 if values[3] < 0 else values[3]\n",
    "                        values[4] = 0.0 if values[4] < 0 else values[4]\n",
    "                        print(f\"Invalid bounding box in {label_path}: {line.strip()}\")\n",
    "                    if len(values) != 5:\n",
    "                        print(f\"Invalid label format in {label_path}: {line.strip()}\")\n",
    "                    new_line = \" \".join(str(v) for v in values) + \"\\n\"\n",
    "                    new_lines.append(new_line)\n",
    "                # Overwrite the original file with the corrected content\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.writelines(new_lines)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13838c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set(model_path, data_yaml_path):\n",
    "    model = YOLO('yolov8n.yaml')\n",
    "    model.load(model_path)\n",
    "    model.val(data=data_yaml_path, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33fdcd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 355/355 items from pretrained weights\n",
      "YOLOv8n summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
      "(129, 3157200, 3157184, 8.8575488)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.yaml')\n",
    "model.load('/snapshots/yolov8n.pt')\n",
    "model.to('cuda')\n",
    "\n",
    "print(model.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2830698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_config = {\n",
    "#     'data': 'data.yaml',\n",
    "#     'epochs': 100,\n",
    "#     'patience': 10,\n",
    "#     'batch': 16,\n",
    "#     'imgsz': 640,\n",
    "#     'save': True,\n",
    "#     'save_period': 1,\n",
    "#     'project': r'./model_runs',\n",
    "#     'name': 'default_augmentation_train',\n",
    "#     'exist_ok': False,\n",
    "#     'seed': 0,\n",
    "#     'resume': True,\n",
    "#     'lr0': 0.1, \n",
    "#     'lrf': 0.001,\n",
    "#     'dropout': 0.0,\n",
    "#     'val': True,\n",
    "#     'plots':True,\n",
    "# }\n",
    "\n",
    "# val_config = {\n",
    "#     'data': 'data.yaml',\n",
    "#     'batch': 16,\n",
    "#     'imgsz': 640,\n",
    "#     'conf': 0.25,\n",
    "#     'iou': 0.5,\n",
    "#     'max_det': 100,\n",
    "#     'plots': True,\n",
    "#     'split': 'val',\n",
    "#     'project': r'./model_runs',\n",
    "#     'name': 'default_augmentation_val'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "124f338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(\n",
    "#     **train_config\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e47672a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.val(\n",
    "#     **val_config\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(box1, box2):\n",
    "    '''pascal format'''\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    union = area_box1 + area_box2 - intersection\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d821fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def parse_results(base_path):\n",
    "    results_path = os.path.join(base_path, 'results.csv')\n",
    "    results = pd.read_csv(results_path)\n",
    "    results['total_train_loss'] = results[['train/box_loss', 'train/cls_loss', 'train/dfl_loss']].sum(axis=1)\n",
    "    results['total_val_loss'] = results[['val/box_loss', 'val/cls_loss', 'val/dfl_loss']].sum(axis=1)\n",
    "    return results\n",
    "\n",
    "results = parse_results(r'./model_runs/default_augmentation_train/')\n",
    "plt.plot(results['epoch'], results['total_train_loss'], label='Train Loss', color='green')\n",
    "plt.plot(results['epoch'], results['total_val_loss'], label='Validation Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = r'./data/test_data/images'\n",
    "\n",
    "# for (root, dirs, file_names) in os.walk(test_path):\n",
    "#     for file in file_names:\n",
    "#         file_path = os.path.join(root, file)\n",
    "#         if \"cache\" in file:\n",
    "#             continue\n",
    "\n",
    "#         model.predict(\n",
    "\n",
    "#             file_path,\n",
    "#             imgsz=640,\n",
    "#             conf=0.25,\n",
    "#             iou=0.5,\n",
    "#             max_det=100,\n",
    "#             save=True,\n",
    "#             save_txt=True,\n",
    "#             project=r'./model_runs/default_augmentation_test',\n",
    "#             name='default_augmentation_test',\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.671866, 0.623762, 0.371998, 0.73051]]\n",
      "[[0.0, 0.631, 0.5900900900900901, 0.362, 0.8138138138138138]]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# predict_run_path = r'model_runs\\default_augmentation_test'\n",
    "# corres_test_path = r'data\\test_data\\labels'\n",
    "\n",
    "# def generate_test_folder_list(test_label_folder):\n",
    "#     test_list = []\n",
    "#     for folder_name in os.listdir(test_label_folder):\n",
    "#         for labels_name in os.listdir(os.path.join(test_label_folder, folder_name)):\n",
    "#             test_list.append(os.path.join(folder_name, labels_name))\n",
    "        \n",
    "#     return test_list\n",
    "\n",
    "# def calc_iou(predicted, target):\n",
    "#     '''predicted is the prediction, target is actual (for error's sake)'''\n",
    "#     xmin = max(0, predicted[1] - predicted[3] / 2)\n",
    "#     ymin = max(0, predicted[2] - predicted[4] / 2)\n",
    "#     xmax = min(1, predicted[1] + predicted[3] / 2)\n",
    "#     ymax = min(1, predicted[2] + predicted[4] / 2)\n",
    "\n",
    "#     pred_box = [xmin, ymin, xmax, ymax]\n",
    "#     target_box = [target[1] - target[3] / 2, target[2] - target[4] / 2, target[1] + target[3] / 2, target[2] + target[4] / 2]\n",
    "\n",
    "#     if pred_box[0] > pred_box[2] or pred_box[1] > pred_box[3]:\n",
    "#         return 0\n",
    "\n",
    "#     intersection = max(0, min(pred_box[2], target_box[2]) - max(pred_box[0], target_box[0])) * max(0, min(pred_box[3], target_box[3]) - max(pred_box[1], target_box[1]))\n",
    "#     union = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1]) + (target_box[2] - target_box[0]) * (target_box[3] - target_box[1]) - intersection\n",
    "\n",
    "#     return intersection / union if union > 0 else 0\n",
    "\n",
    "# def max_iou(predicted_label, target_label):\n",
    "#     with open(predicted_label, 'r') as pred_file:\n",
    "#         pred_lines = pred_file.readlines()\n",
    "#     with open(target_label, 'r') as target_file:\n",
    "#         target_lines = target_file.readlines()\n",
    "\n",
    "#     pred_boxes = [list(map(float, line.strip().split(\" \"))) for line in pred_lines]\n",
    "#     target_boxes = [list(map(float, line.strip().split(\" \"))) for line in target_lines]\n",
    "#     print(pred_boxes)\n",
    "#     print(target_boxes)\n",
    "\n",
    "\n",
    "# def calculate_prediction_metrics(predict_run_path, corres_test_path):\n",
    "#     test_list = generate_test_folder_list(corres_test_path)\n",
    "\n",
    "#     for augmentation_test_num in os.listdir(predict_run_path):\n",
    "#         test_run_path = os.path.join(predict_run_path, augmentation_test_num)\n",
    "#         for item_name in os.listdir(test_run_path):\n",
    "#             if os.path.isfile(os.path.join(test_run_path, item_name)):\n",
    "#                 image_path = item_name\n",
    "#                 continue\n",
    "        \n",
    "#         file_title, _ = os.path.splitext(image_path)\n",
    "#         label_title = file_title + '.txt'\n",
    "#         predicted_label = os.path.join(test_run_path, \"labels\", label_title)\n",
    "\n",
    "#         if not os.path.exists(predicted_label):\n",
    "#             print(f\"Missing predicted label file for {label_title} in {predicted_label}\")\n",
    "#             continue\n",
    "\n",
    "#         for test_label in test_list:\n",
    "#             if label_title in test_label:\n",
    "#                 target_label = os.path.join(corres_test_path, test_label)\n",
    "#                 break\n",
    "\n",
    "#         max_iou(predicted_label, target_label)\n",
    "#         break\n",
    "    \n",
    "# calculate_prediction_metrics(predict_run_path, corres_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.yaml')\n",
    "model.load('/snapshots/yolov8n.pt')\n",
    "model.to('cuda')\n",
    "\n",
    "print(model.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ee9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleless_class_dict = {}\n",
    "ctr = 0\n",
    "for category_name in os.listdir(IMG_PATH):\n",
    "    if category_name == \"People\":\n",
    "        continue\n",
    "    peopleless_class_dict[category_name] = ctr\n",
    "    ctr += 1\n",
    "print(peopleless_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c040caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pascal_to_yolo_without_person(image_path):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    image_dir = os.path.dirname(image_path).replace(\"\\\\\", \"/\")\n",
    "    file_title, _ = os.path.splitext(image_name)\n",
    "    yolo_anno_path = image_dir.replace(\"images\", \"labels\") + f\"/{file_title}.txt\"\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img_height, img_width = img.shape[:2]\n",
    "\n",
    "    sub_category = image_dir.split(\"/\")[-1]\n",
    "    path_from_base = os.path.join(sub_category, image_name)\n",
    "    \n",
    "    original_annotation_path = os.path.join(ANNOTATION_PATH, path_from_base + \".txt\")\n",
    "    with open(original_annotation_path, 'r') as anno_file:\n",
    "        pascal_data = anno_file.readlines()[1:]\n",
    "\n",
    "    pascal_num = list(map(lambda s: s.strip().split(\" \")[:5], pascal_data))\n",
    "    \n",
    "    yolo_format = []\n",
    "    for indv_bounding_coordinates in pascal_num:\n",
    "        if indv_bounding_coordinates[0].lower() == \"people\":\n",
    "            continue\n",
    "        \n",
    "        indv_bounding_coordinates[0] = peopleless_class_dict[indv_bounding_coordinates[0]]\n",
    "        indv_bounding_coordinates[1:] = list(map(int, indv_bounding_coordinates[1:]))\n",
    "        # print(indv_bounding_coordinates)\n",
    "\n",
    "        class_category = indv_bounding_coordinates[0]\n",
    "        x_ctr = min((indv_bounding_coordinates[1] + indv_bounding_coordinates[3]/2) / img_width, 1.0)\n",
    "        y_ctr = min((indv_bounding_coordinates[2] + indv_bounding_coordinates[4]/2) / img_height, 1.0)\n",
    "        width = min((indv_bounding_coordinates[3]) / img_width, 1.0)\n",
    "        height = min((indv_bounding_coordinates[4]) / img_height, 1.0)\n",
    "        yolo_format.append([class_category, x_ctr, y_ctr, width, height])\n",
    "    \n",
    "    if len(yolo_format) == 0:\n",
    "        os.remove(image_path)\n",
    "        print(f\"Removed {image_path} because no bounding box found\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(os.path.dirname(yolo_anno_path), exist_ok=True)\n",
    "    with open(yolo_anno_path, 'w') as yolo_writer:\n",
    "        for data in yolo_format:\n",
    "            yolo_writer.write(f\"{' '.join(list(map(str, data)))}\\n\")\n",
    "    \n",
    "    print(f\"Converted to {image_path} and label {yolo_anno_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test_peopleless(src_path, train_path, val_path, test_path, split_ratio, function=None, seed=None):\n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "    if not os.path.exists(val_path):\n",
    "        os.makedirs(val_path, exist_ok=True)\n",
    "    if not os.path.exists(test_path):\n",
    "        os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "    if os.listdir(train_path) != []:\n",
    "        shutil.rmtree(train_path)\n",
    "        print(f\"Removed existing train path: {train_path}\")\n",
    "    if os.listdir(val_path) != []:\n",
    "        shutil.rmtree(val_path)\n",
    "        print(f\"Removed existing val path: {val_path}\")\n",
    "    if os.listdir(test_path) != []:\n",
    "        shutil.rmtree(test_path)\n",
    "        print(f\"Removed existing test path: {test_path}\")\n",
    "    \n",
    "    if seed != None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    file_lists = []\n",
    "    for (root, _, file_names) in os.walk(src_path):\n",
    "        if file_names == []:\n",
    "            continue\n",
    "\n",
    "        sub_folder_name = os.path.basename(root)\n",
    "\n",
    "        file_path_list = list(map(lambda path: os.path.join(sub_folder_name, path), file_names))\n",
    "\n",
    "        random.shuffle(file_path_list)\n",
    "        file_lists.append(file_path_list)\n",
    "\n",
    "    for category_specific_list in file_lists:\n",
    "        for file_name in category_specific_list:\n",
    "            random_num = random.random()\n",
    "\n",
    "            if random_num < split_ratio[0]:\n",
    "                move_path = os.path.join(train_path, os.path.dirname(file_name))\n",
    "            elif random_num < sum(split_ratio[:2]):\n",
    "                move_path = os.path.join(val_path, os.path.dirname(file_name)) \n",
    "            else:\n",
    "                move_path = os.path.join(test_path, os.path.dirname(file_name))\n",
    "\n",
    "            os.makedirs(move_path, exist_ok=True)            \n",
    "            original_path = os.path.join(src_path, file_name)\n",
    "            new_name = os.path.join(move_path, os.path.basename(file_name))\n",
    "            shutil.copy(original_path, move_path)\n",
    "            if function != None:\n",
    "                function(move_path)\n",
    "                \n",
    "\n",
    "            pascal_to_yolo_without_person(new_name)\n",
    "            \n",
    "            print(f\"{original_path} --> {new_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleless_dataset = './data/people_remove_train_val/images'\n",
    "\n",
    "generate_train_val_test_peopleless(\n",
    "    src_path='./data/img_dataset',\n",
    "    train_path=os.path.join(peopleless_dataset, 'train'),\n",
    "    val_path=os.path.join(peopleless_dataset, 'val'),\n",
    "    test_path='./data/people_remove_test_data/images',\n",
    "    split_ratio=train_val_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_removed_train_config = {\n",
    "    'data': 'people_balanced_data.yaml',\n",
    "    'epochs': 100,\n",
    "    'patience': 10,\n",
    "    'batch': 16,\n",
    "    'imgsz': 640,\n",
    "    'save': True,\n",
    "    'save_period': 1,\n",
    "    'project': r'./model_runs',\n",
    "    'name': 'people_removed_train',\n",
    "    'exist_ok': False,\n",
    "    'seed': 0,\n",
    "    'resume': True,\n",
    "    'lr0': 0.1, \n",
    "    'lrf': 0.001,\n",
    "    'dropout': 0.0,\n",
    "    'val': True,\n",
    "    'plots':True,\n",
    "}\n",
    "\n",
    "people_removed_val_config = {\n",
    "    'data': 'people_balanced_data.yaml',\n",
    "    'batch': 16,\n",
    "    'imgsz': 640,\n",
    "    'conf': 0.25,\n",
    "    'iou': 0.5,\n",
    "    'max_det': 100,\n",
    "    'plots': True,\n",
    "    'split': 'val',\n",
    "    'project': r'./model_runs',\n",
    "    'name': 'people_removed_val'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079788d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    **people_removed_train_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val(\n",
    "    **people_removed_val_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d200e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 319/355 items from pretrained weights\n",
      "Ultralytics 8.3.107  Python-3.10.5 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 3070 Ti, 8192MiB)\n",
      "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 31,920 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "\u001b[34m\u001b[1mval: \u001b[0mError loading data from None\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\data\\base.py:156\u001b[0m, in \u001b[0;36mBaseDataset.get_img_files\u001b[1;34m(self, img_path)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m img_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img_path, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [img_path]:\n\u001b[1;32m--> 156\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# os-agnostic\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir():  \u001b[38;5;66;03m# dir\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m--> 594\u001b[0m drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43meval_on_test_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDuenoHfao\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mWork\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSCVU\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmlgp_full\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel_runs\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpeople_removed_train\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbest.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpeople_balanced_data.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36meval_on_test_set\u001b[1;34m(model_path, data_yaml_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8n.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:628\u001b[0m, in \u001b[0;36mModel.val\u001b[1;34m(self, validator, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m    627\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m--> 628\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\engine\\validator.py:190\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mrect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstride  \u001b[38;5;66;03m# used in get_dataloader() for padding\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    193\u001b[0m model\u001b[38;5;241m.\u001b[39mwarmup(imgsz\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch, \u001b[38;5;241m3\u001b[39m, imgsz, imgsz))  \u001b[38;5;66;03m# warmup\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:317\u001b[0m, in \u001b[0;36mDetectionValidator.get_dataloader\u001b[1;34m(self, dataset_path, batch_size)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_path, batch_size):\n\u001b[0;32m    307\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    Construct and return dataloader.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m        (torch.utils.data.DataLoader): Dataloader for validation.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_dataloader(dataset, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworkers, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:304\u001b[0m, in \u001b[0;36mDetectionValidator.build_dataset\u001b[1;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    Build YOLO Dataset.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m        (Dataset): YOLO dataset.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_yolo_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\data\\build.py:109\u001b[0m, in \u001b[0;36mbuild_yolo_dataset\u001b[1;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m dataset \u001b[38;5;241m=\u001b[39m YOLOMultiModalDataset \u001b[38;5;28;01mif\u001b[39;00m multi_modal \u001b[38;5;28;01melse\u001b[39;00m YOLODataset\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# augmentation\u001b[39;49;00m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: probably add a get_hyps_from_cfg function\u001b[39;49;00m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# rectangular batches\u001b[39;49;00m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorstr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfraction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\data\\dataset.py:87\u001b[0m, in \u001b[0;36mYOLODataset.__init__\u001b[1;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_segments \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_keypoints), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not use both segments and keypoints.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\data\\base.py:107\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[1;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;241m=\u001b[39m prefix\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfraction \u001b[38;5;241m=\u001b[39m fraction\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_img_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_labels()\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_labels(include_class\u001b[38;5;241m=\u001b[39mclasses)  \u001b[38;5;66;03m# single_cls and include_class\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\.venv\\lib\\site-packages\\ultralytics\\data\\base.py:172\u001b[0m, in \u001b[0;36mBaseDataset.get_img_files\u001b[1;34m(self, img_path)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m im_files, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mNo images found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFORMATS_HELP_MSG\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mError loading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mHELP_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfraction \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    174\u001b[0m     im_files \u001b[38;5;241m=\u001b[39m im_files[: \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mlen\u001b[39m(im_files) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfraction)]  \u001b[38;5;66;03m# retain a fraction of the dataset\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: \u001b[34m\u001b[1mval: \u001b[0mError loading data from None\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
     ]
    }
   ],
   "source": [
    "eval_on_test_set(\n",
    "    r'C:\\Users\\DuenoHfao\\Desktop\\Work\\SCVU\\mlgp_full\\model_runs\\people_removed_train\\weights\\best.pt'\n",
    "    , 'people_balanced_data.yaml'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
