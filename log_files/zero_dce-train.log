ERROR:__main__:Sun, 13 Apr 2025, 04:57:11: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 963, 1912] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:57:15: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 828.81 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 85.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:16: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 7.92 GiB of which 829.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 4.58 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:17: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 829.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 85.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:18: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 829.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 85.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:19: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 827.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 85.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:20: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 827.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 574.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:21: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 512, 1024] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:57:24: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 645, 1278] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:57:24: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 827.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 574.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:25: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 827.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 85.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:25: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 7.92 GiB of which 827.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 4.58 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:26: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:57:28: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 7.92 GiB of which 827.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 4.58 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:28: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 827.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 85.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:29: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 7.92 GiB of which 331.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.83 GiB is allocated by PyTorch, and 72.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:30: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:57:31: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 331.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:33: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 331.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:33: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 331.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:34: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:35: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 581.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:36: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:36: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 636, 1279] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:57:37: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.58 GiB is allocated by PyTorch, and 2.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:38: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:41: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:42: CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 581.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:44: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.83 GiB is allocated by PyTorch, and 72.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:45: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 961, 1920] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:57:46: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:47: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:47: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 706, 1710] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:57:49: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:49: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:49: CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacity of 7.92 GiB of which 329.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:50: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:52: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:52: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:53: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:53: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 915, 1609] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:57:53: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:54: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:54: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:55: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:55: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.26 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:56: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 329.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:57:58: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 320.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:01: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 296.81 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:03: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 301.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:03: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 301.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:04: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 301.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:05: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 301.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:06: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 313.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:08: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 314.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:08: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 314.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:11: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 897, 1719] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:12: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 315.38 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:15: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 312.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:16: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 312.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:16: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 312.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:16: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 915, 1757] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:18: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 312.38 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:18: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 312.44 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:20: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 309.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:22: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 314.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:25: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 316.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:26: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 351, 443] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:27: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 311.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:30: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 310.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:31: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:58:32: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 449, 636] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:34: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 308.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:36: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 313.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:37: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 351, 440] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:40: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:58:41: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 352, 444] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:42: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:58:43: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 485, 687] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:44: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 303.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:46: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 302.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:46: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 653, 1279] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:58:49: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 7.92 GiB of which 328.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.44 GiB is allocated by PyTorch, and 3.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:49: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 326.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:51: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 326.75 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:52: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 330.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:55: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 7.92 GiB of which 327.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.23 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:57: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 7.92 GiB of which 325.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.24 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:57: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:58:58: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacity of 7.92 GiB of which 307.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.39 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:58:59: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:59:00: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 310.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:01: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 311.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:06: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 246.75 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:07: CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 7.92 GiB of which 243.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.45 GiB is allocated by PyTorch, and 2.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:08: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 241.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:09: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 203.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:12: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:59:12: CUDA out of memory. Tried to allocate 2.41 GiB. GPU 0 has a total capacity of 7.92 GiB of which 210.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.93 GiB is allocated by PyTorch, and 1.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:13: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.38 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:14: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:59:14: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 228.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:20: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:22: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.58 GiB is allocated by PyTorch, and 2.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:22: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 2.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:25: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 355, 719] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:59:25: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:27: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 338, 500] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:59:28: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:29: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:29: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 359, 719] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:59:29: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:30: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:36: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:36: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:38: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 1045, 764] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:59:39: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 243.62 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:39: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 243.62 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:40: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 7.92 GiB of which 243.62 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.24 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:40: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 243.62 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:41: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 313, 622] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:59:41: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 243.62 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:44: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 04:59:45: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 243.62 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 04:59:52: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 481, 1278] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 04:59:58: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 476, 1279] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:03: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:00:06: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 232.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:07: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 232.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:08: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 232.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:08: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 232.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:09: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 203.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.96 GiB is allocated by PyTorch, and 964.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:09: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 206.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:10: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 206.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:10: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 207.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:11: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 7.92 GiB of which 215.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.58 GiB is allocated by PyTorch, and 2.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:12: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 7.92 GiB of which 212.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.83 GiB is allocated by PyTorch, and 72.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:13: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 213.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:14: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 226.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:15: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 647, 1280] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:15: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 226.75 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:16: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 7.92 GiB of which 226.75 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.58 GiB is allocated by PyTorch, and 2.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:18: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 751, 747] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:18: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 225.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:19: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:00:19: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.03 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:20: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.83 GiB is allocated by PyTorch, and 72.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:21: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 566, 1280] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:21: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:22: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:22: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 647, 1279] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:23: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:23: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 404, 720] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:24: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:24: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 629, 1280] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:28: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 636, 1278] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:29: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 221.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:29: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 221.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:30: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 207.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:31: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 191.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:31: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 190.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:32: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 190.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:32: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 190.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:32: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 191.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:32: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 191.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:34: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 196.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:36: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 942, 1788] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:36: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 195.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:37: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 192.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:38: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.50 GiB is allocated by PyTorch, and 2.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:38: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 638, 1280] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:38: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 961, 1881] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:39: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:39: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:40: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:40: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:40: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:00:41: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:41: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:41: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 477, 1279] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:41: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:42: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 200.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:43: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 200.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:43: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 197.31 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:44: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 208.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:46: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 209.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:47: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 209.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:48: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 163.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:48: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 165.25 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:49: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 660, 800] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:50: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 7.92 GiB of which 165.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 2.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:51: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 204.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:52: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 221.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:53: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacity of 7.92 GiB of which 221.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.20 GiB is allocated by PyTorch, and 718.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:53: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:54: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:54: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:55: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:56: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:56: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 637, 861] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:56: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:57: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:58: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:00:58: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 655, 1279] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:00:59: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:00: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:00: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 227.12 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:01: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:01: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:02: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:03: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:03: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 652, 994] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:01:03: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:04: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:04: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:05: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:06: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:07: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:09: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 450, 767] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:01:09: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:11: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:12: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:13: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:15: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:16: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:01:17: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:17: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:18: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:19: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 237.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:20: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 513, 684] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:01:22: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 235.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:23: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 235.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:25: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:27: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:28: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 2.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:28: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:01:28: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:29: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:30: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:30: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:31: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 217.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:31: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 216.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:34: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:36: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 402, 516] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:01:36: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 166.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:40: CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 7.92 GiB of which 175.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.16 GiB is allocated by PyTorch, and 759.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:41: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 175.81 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:41: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 7.92 GiB of which 185.00 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.78 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:44: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 185.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:44: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 7.92 GiB of which 196.88 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 6.83 GiB is allocated by PyTorch, and 72.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:46: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 172.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:47: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 180.56 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:51: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 202.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:53: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 192.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:54: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:01:54: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:55: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.07 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:56: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:56: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:01:59: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:00: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:01: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:01: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:02:02: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:04: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 184.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:06: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 190.81 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:09: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 190.81 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:10: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 660, 1023] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:02:14: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:02:14: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:02:15: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 166.38 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:18: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 171.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:19: CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 7.92 GiB of which 171.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:20: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 168.94 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:21: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 173.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:25: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 437, 551] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:02:25: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 597, 746] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:02:27: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 178.50 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:29: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:02:37: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:02:40: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 7.92 GiB of which 151.75 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:43: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 478, 693] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:02:43: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 479, 789] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:02:44: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacity of 7.92 GiB of which 199.19 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:51: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:02:53: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacity of 7.92 GiB of which 183.06 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:56: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 7.92 GiB of which 161.69 MiB is free. Process 5375 has 105.74 MiB memory in use. Including non-PyTorch memory, this process has 7.02 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR:__main__:Sun, 13 Apr 2025, 05:02:57: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
ERROR:__main__:Sun, 13 Apr 2025, 05:02:59: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 435, 701] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:03:01: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 600, 800] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:03:02: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 4, 600, 800] to have 3 channels, but got 4 channels instead
ERROR:__main__:Sun, 13 Apr 2025, 05:03:03: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3
